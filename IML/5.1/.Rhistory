ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
b$likelihood
b$likelihood[[1]]
b$likelihood[[1]][g[1,1]][]
b$likelihood[[1]][g[1,1]]
b$likelihood[[1]][g[1,1], g[1,2]]
b$likelihood[[1]][g[1,1]+1, g[1,2]+1]
b$likelihood[[1]][g[1,1]+1, g[1,2]+1] = 3
b$likelihood
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
g = expand.grid(0:n_class_x[1]-1, 0:n_class_x[2]-1)
for(i in 1:length(grid)){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
b$likelihood
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
g = expand.grid(0:n_class_x[1]-1, 0:n_class_x[2]-1)
for(i in 1:length(grid)){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print(likelihood[[c+1]][g[i,1]+1, g[i,2]+1])
likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
g = expand.grid(0:n_class_x[1]-1, 0:n_class_x[2]-1)
for(i in 1:length(grid)){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print(g[i,1]+1, g[i,2]+1)
likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
g = expand.grid(0:n_class_x[1]-1, 0:n_class_x[2]-1)
for(i in 1:length(grid)){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print(1)
#likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
g = expand.grid(0:n_class_x[1]-1, 0:n_class_x[2]-1)
for(i in 1:length(g)){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
b$likelihood
b = bayes(train$Y, train$X)
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
g = expand.grid(0:n_class_x[1]-1, 0:n_class_x[2]-1)
for(i in 1:length(g)){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print(g[i,1]+1, g[i,2]+1)
likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
g[0,0]
g[1,1]
g[1,1]+1
g
g[1,1]+1
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
g = expand.grid(0:n_class_x[1]-1, 0:n_class_x[2]-1)
for(i in 1:length(g)){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print(g[i,1]+1)
likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
g = expand.grid(0:n_class_x[1]-1, 0:n_class_x[2]-1)
for(i in 1:length(g)){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print(g[i,1]+1)
likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
g = expand.grid(0:n_class_x[1]-1, 0:n_class_x[2]-1)
for(i in 1:length(g)){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print(g[i,1])
likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
b = bayes(train$Y, train$X)
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
g = expand.grid(0:(n_class_x[1]-1), 0:(n_class_x[2]-1))
print(g)
for(i in 1:length(g)){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
g = expand.grid(0:(n_class_x[1]-1), 0:(n_class_x[2]-1))
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
for(i in 1:length(g)){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
b$likelihood
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
g = expand.grid(0:(n_class_x[1]-1), 0:(n_class_x[2]-1))
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
for(i in 1:length(g)){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print(n_cj)
likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
g = expand.grid(0:(n_class_x[1]-1), 0:(n_class_x[2]-1))
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
for(i in 1:length(g[,1])){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print(n_cj)
likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
b$likelihood
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
g = expand.grid(0:(n_class_x[1]-1), 0:(n_class_x[2]-1))
print(g)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
for(i in 1:length(g[,1])){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
likelihood[[c+1]][g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
g = expand.grid(0:(n_class_x[1]-1), 0:(n_class_x[2]-1))
print(g)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
for(i in 1:length(g[,1])){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print(g[i,1])
print(g[i,2])
likelihood[[c+1]][ g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
g = expand.grid(0:(n_class_x[1]-1), 0:(n_class_x[2]-1))
print(g)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
for(i in 1:length(g[,1])){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print(g[i,1])
print(g[i,2])
likelihood[[c+1]][ g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
g = expand.grid(0:(n_class_x[1]-1), 0:(n_class_x[2]-1))
print(g)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
for(i in 1:length(g[,1])){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print((n_cj + m) / (n_c + n_class_x[i] * m)    )
likelihood[[c+1]][ g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + n_class_x[i] * m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
g = expand.grid(0:(n_class_x[1]-1), 0:(n_class_x[2]-1))
print(g)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
for(i in 1:length(g[,1])){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print((n_cj + m) / (n_c + length(grid[,1])* m))
likelihood[[c+1]][ g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + length(grid[,1])* m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
g = expand.grid(0:(n_class_x[1]-1), 0:(n_class_x[2]-1))
print(g)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
for(i in 1:length(g[,1])){
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print((n_cj + m) / (n_c + length(g[,1])* m))
likelihood[[c+1]][ g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + length(g[,1])* m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
b$likelihood
bayes <- function(Y, X, n_class = 3, n_class_x = c(2,3), m = 0) {
n <- length(Y)
likelihood <- vector('list', length = n_class)
prior <- numeric(n_class)
g = expand.grid(0:(n_class_x[1]-1), 0:(n_class_x[2]-1))
print(g)
for(c in 0:(n_class-1)) {
n_c <- sum(Y == c)
prior[c+1] <- (n_c + m) / (n + n_class * m)
likelihood[[c+1]] <- matrix(rep(0, n_class_x[1] * n_class_x[2]), nrow=n_class_x[1])
for(i in 1:length(g[,1])){
n_cj <- sum(Y == c & X[ ,1] == g[i,1] & X[ ,2] == g[i,2])
print((n_cj + m) / (n_c + length(g[,1])* m))
likelihood[[c+1]][ g[i,1]+1, g[i,2]+1] <- (n_cj + m) / (n_c + length(g[,1])* m)
}
}
ret <- list(prior = prior, likelihood = likelihood, n_class = n_class, n_class_x = n_class_x)
class(ret) <- 'nb'
ret
}
b = bayes(train$Y, train$X)
b$l
b$likelihood
predict.bayes <- function(bfit, x){
n <- nrow(X)
prob <- matrix(0, nrow = n, ncol = nfit$n_class)
for(i in 1:n)                 # compute joint probabilities p(x,y)
for(c in 1:nfit$n_class) {
prob[i,c] <- nfit$prior[c] * nfit$likelihood[[c]][X[i,1] + 1, x[i,2]+1]
}
prob <- prob / rowSums(prob)      # normalize into conditional probabilities p(y|x)
pred <- max.col(prob) - 1        # predict class y as argmax p(y|x)
if(probabilities) prob else pred
}
predict.bayes(b, test$X[1:10])
predict.bayes <- function(bfit, x){
n <- nrow(X)
prob <- matrix(0, nrow = n, ncol = bfit$n_class)
for(i in 1:n)                 # compute joint probabilities p(x,y)
for(c in 1:bfit$n_class) {
prob[i,c] <- bfit$prior[c] * bfit$likelihood[[c]][X[i,1] + 1, x[i,2]+1]
}
prob <- prob / rowSums(prob)      # normalize into conditional probabilities p(y|x)
pred <- max.col(prob) - 1        # predict class y as argmax p(y|x)
if(probabilities) prob else pred
}
predict.bayes(b, test$X[1:10])
predict.bayes(b, test$X[1:10, ])
test$X[1:10, ]
predict.bayes <- function(bfit, x){
n <- nrow(X)
prob <- matrix(0, nrow = n, ncol = bfit$n_class)
for(i in 1:n)                 # compute joint probabilities p(x,y)
for(c in 1:bfit$n_class) {
prob[i,c] <- bfit$prior[c] * bfit$likelihood[[c]][X[i,1] + 1, X[i,2]+1]
}
prob <- prob / rowSums(prob)      # normalize into conditional probabilities p(y|x)
pred <- max.col(prob) - 1        # predict class y as argmax p(y|x)
if(probabilities) prob else pred
}
predict.bayes(b, test$X[1:10, ])
predict.bayes <- function(bfit, x, probabilities = TRUE){
n <- nrow(X)
prob <- matrix(0, nrow = n, ncol = bfit$n_class)
for(i in 1:n)                 # compute joint probabilities p(x,y)
for(c in 1:bfit$n_class) {
prob[i,c] <- bfit$prior[c] * bfit$likelihood[[c]][X[i,1] + 1, X[i,2]+1]
}
prob <- prob / rowSums(prob)      # normalize into conditional probabilities p(y|x)
pred <- max.col(prob) - 1        # predict class y as argmax p(y|x)
if(probabilities) prob else pred
}
predict.bayes(b, test$X[1:10, ])
test$X[!:!0]
test$X[1:10, ]
predict.bayes(b, test$X[1:10, ])
source('script.r')
source('script.r')
b = bayes(train$X, train$Y)
b = bayes(train$Y, train$X)
predict(b, test$X, probabilities = FALSE) == test$Y
pred = predict(b, test$X, probabilities = FALSE)
pred
prob = predict(b, test$X, probabilities = TRUE)
prob
prob[1:10, ]
test$X[1:10]
test$X[1:10,]
test$Y[1:10]
pred[1:10]
pred[1:20]
prob[1:20, ]
length(pred)
length(test$Y)
prob = predict.bayes(b, test$X, probabilities = TRUE)
prob[1:10, ]
nrow(test$X)
nrow(prob)
source('script.r')
source('script.r')
b = bayes(train$Y, train$X)
g = expand.grid(0:1, 0:2)
g
predict(b, g)
